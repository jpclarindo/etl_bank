{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Necessário possuir a biblioteca DuckDB, holidays e babel instaladas.\n",
        "!pip install duckdb\n",
        "!pip install babel\n",
        "!pip install holidays\n",
        "!pip install gdown"
      ],
      "metadata": {
        "id": "Tr1eaFJpWH5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting Github files if this notebook is executed in a Google Colab environment.\n",
        "if 'google.colab' in sys.modules:\n",
        "  temp_folder = \"etl_bank\"\n",
        "\n",
        "  !git clone -b 'dev' 'https://github.com/jpclarindo/etl_bank.git' $temp_folder\n",
        "  !rsync -a $temp_folder/ .\n",
        "  !rm -rf $temp_folder\n"
      ],
      "metadata": {
        "id": "VyymwT9V7ehm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important! Google Drive Link for data source is required to execute this notebook. Please, put the link in gdrive_link.txt at the root."
      ],
      "metadata": {
        "id": "ovHkkl2sndSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import duckdb\n",
        "import src.utils as utils\n",
        "\n",
        "# Libraries to create date dimension\n",
        "from datetime import datetime, timedelta\n",
        "from babel.dates import format_date, format_datetime, format_time\n",
        "import holidays\n",
        "\n",
        "# Auxiliar libraries\n",
        "import time\n",
        "import json\n",
        "import os, sys, glob"
      ],
      "metadata": {
        "id": "Y15PykOQV7QI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init DuckDB connection.\n",
        "con = duckdb.connect(database='database.duckdb', read_only=False)\n",
        "\n",
        "# Creating cleaning function mapping for each attribute\n",
        "cleaning_mapping = json.load(open('src/function_mapping.json','r',encoding='utf-8'))"
      ],
      "metadata": {
        "id": "0DARAeUyXUl1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating time and date dimension tables."
      ],
      "metadata": {
        "id": "jK375AmzY9_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPpqRpg-4X5u",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def create_time_dimension_table():\n",
        "  time_list = []\n",
        "  time_of_day = ['Early Morning', 'Morning', 'Afternoon', 'Night']\n",
        "  time_of_day_pt = ['Madrugada', 'Manhã', 'Tarde', 'Noite']\n",
        "\n",
        "  for i in range(86400):\n",
        "    min_sec = i % 3600\n",
        "\n",
        "    time_dict = {'tempo_id': i+1,\n",
        "                'hora': i // 3600,\n",
        "                'minuto': min_sec // 60,\n",
        "                'segundo': min_sec % 60\n",
        "                }\n",
        "\n",
        "    time_dict['periodo_en'] = time_of_day[time_dict['hora'] // 6]\n",
        "    time_dict['periodo_pt'] = time_of_day_pt[time_dict['hora'] // 6]\n",
        "    time_dict['formatado'] = f\"{time_dict['hora']:02d}:{time_dict['minuto']:02d}:{time_dict['segundo']:02d}\"\n",
        "\n",
        "    time_list.append(time_dict)\n",
        "\n",
        "\n",
        "  time_df = pd.DataFrame(time_list)\n",
        "  con.execute(\"\"\"CREATE TABLE IF NOT EXISTS d_tempo\n",
        "                 AS SELECT * FROM time_df\"\"\")\n",
        "\n",
        "  print('Time dimension created and inserted in the database')\n",
        "  return True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def create_date_dimension_table():\n",
        "  date_list = []\n",
        "  start_date =  datetime(1950, 1, 1)\n",
        "  end_date = datetime(2050, 12, 31)\n",
        "  delta = timedelta(days=1)\n",
        "  count = 0\n",
        "\n",
        "  while start_date <= end_date:\n",
        "    count += 1\n",
        "\n",
        "    date_dict = {'data_id': count,\n",
        "                'formatado': start_date.strftime('%Y-%m-%d'),\n",
        "                'ano': start_date.year,\n",
        "                'trimestre': format_date(start_date,'Q'),\n",
        "                'nome_trimestre_en': format_date(start_date, format='QQQQ', locale='en_US'),\n",
        "                'nome_trimestre_pt': format_date(start_date, format='QQQQ', locale='pt_BR'),\n",
        "                'mes': start_date.month,\n",
        "                'nome_mes_en': format_date(start_date, format='MMMM', locale='en_US'),\n",
        "                'nome_mes_pt': format_date(start_date, format='MMMM', locale='pt_BR'),\n",
        "                'dia': start_date.day,\n",
        "                'nome_dia_en': format_date(start_date, format='EEEE', locale='en_US'),\n",
        "                'nome_dia_pt': format_date(start_date, format='EEEE', locale='pt_BR'),\n",
        "                'fim_de_semana': 1 if start_date.weekday() in [5, 6] else 0,\n",
        "                'feriado': 1 if start_date.strftime('%Y-%m-%d') in holidays.Brazil() else 0\n",
        "    }\n",
        "\n",
        "    print(date_dict)\n",
        "\n",
        "    start_date += delta\n",
        "    date_list.append(date_dict)\n",
        "\n",
        "  date_df = pd.DataFrame(date_list)\n",
        "  con.execute(\"\"\"CREATE TABLE IF NOT EXISTS d_data\n",
        "                 AS SELECT * FROM date_df\"\"\")\n"
      ],
      "metadata": {
        "id": "uSoC-AY0ZCgl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ETL Processing - Extraction"
      ],
      "metadata": {
        "id": "5xRpW9gXe1Al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_raw_data():\n",
        "  #\n",
        "  utils.download_data()\n",
        "\n",
        "  # Adding files through a dict\n",
        "  dfs_raw = {}\n",
        "\n",
        "  file_list = glob.glob('data/*.csv')\n",
        "\n",
        "  for csv_file in file_list:\n",
        "    df = pd.read_csv(csv_file, sep=',', encoding='utf-8')\n",
        "\n",
        "    # Metadata for extraction\n",
        "    df['_load_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    df['_file_name'] = os.path.basename(csv_file)\n",
        "\n",
        "    dfs_raw[os.path.basename(csv_file).replace('.csv','')] = df\n",
        "\n",
        "  return dfs_raw\n",
        "\n",
        "dfs_raw = get_raw_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u3PGCFqez3N",
        "outputId": "e7bf3aa2-983a-4a6d-ba61-c47706e07a70"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16jF2hJHVOwikmgoEKs9wARnrE_j6Y7e2\n",
            "To: /content/data.zip\n",
            "100%|██████████| 1.24M/1.24M [00:00<00:00, 94.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ETL - Cleaning"
      ],
      "metadata": {
        "id": "x04Nf87aCUll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning_attributes(df):\n",
        "    \"\"\"\n",
        "    Limpa um DataFrame dinamicamente baseando-se nas regras do JSON.\n",
        "    \"\"\"\n",
        "    df_clean = df.copy()\n",
        "    current_columns = set(df_clean.columns)\n",
        "\n",
        "    for column, function_name in cleaning_mapping['multiple_attrs'].items():\n",
        "\n",
        "        if column in current_columns:\n",
        "            if hasattr(utils, function_name):\n",
        "                func = getattr(utils, function_name)\n",
        "                print(f\"   -> Expanding column '{column}' usando '{function_name}'\")\n",
        "\n",
        "                # Aplica a função que retorna dict\n",
        "                column_dicts = df_clean[column].apply(func)\n",
        "\n",
        "                # Transforma a coluna de dicts em um novo DataFrame de colunas\n",
        "                df_expanded = pd.json_normalize(column_dicts)\n",
        "\n",
        "                # Concatena com o original (axis=1 coloca as colunas ao lado)\n",
        "                df_clean = pd.concat([df_clean, df_expanded], axis=1)\n",
        "\n",
        "                # (Opcional) Remove a coluna original suja para economizar espaço\n",
        "                df_clean.drop(columns=[column], inplace=True)\n",
        "            else:\n",
        "                print(f\"   ⚠️ Aviso: Função '' não encontrada\")\n",
        "\n",
        "\n",
        "    # print(f\"⚙️ Processando tabela: {nome_tabela}\")\n",
        "\n",
        "    # # --- 1. Regras Simples (1 para 1) ---\n",
        "    # # Ex: 'nome' -> clean_text(valor)\n",
        "    # for coluna_alvo, nome_funcao in CONFIG_LIMPEZA['regras_simples'].items():\n",
        "\n",
        "    #     if coluna_alvo in colunas_existentes:\n",
        "    #         # A MÁGICA: getattr busca a função dentro de utils pelo nome (string)\n",
        "    #         if hasattr(utils, nome_funcao):\n",
        "    #             funcao_real = getattr(utils, nome_funcao)\n",
        "\n",
        "    #             print(f\"   -> Aplicando '{nome_funcao}' na coluna '{coluna_alvo}'\")\n",
        "    #             df_clean[coluna_alvo] = df_clean[coluna_alvo].apply(funcao_real)\n",
        "    #         else:\n",
        "    #             print(f\"   ⚠️ Aviso: Função '{nome_funcao}' não encontrada em utils.py\")\n",
        "\n",
        "    # # --- 2. Regras de Expansão (1 para N) ---\n",
        "    # # Ex: 'endereco' -> {rua: ..., cep: ...} -> Colunas novas\n",
        "\n",
        "\n",
        "    return df_clean"
      ],
      "metadata": {
        "id": "Pd8p9tJfA4W-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cob = cleaning_attributes(dfs_raw['colaboradores'])\n",
        "cob.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "E-Lkvu-CFavk",
        "outputId": "c1f677d6-af45-496e-a02b-152bda01f5c4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   -> Expanding column 'endereco' usando 'get_address_dict'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'address_dict' where it is not associated with a value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2717789261.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaning_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'colaboradores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1386433195.py\u001b[0m in \u001b[0;36mcleaning_attributes\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m# Aplica a função que retorna dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mcolumn_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m# Transforma a coluna de dicts em um novo DataFrame de colunas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     def _reindex_indexer(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n",
            "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/content/src/utils.py\u001b[0m in \u001b[0;36mget_address_dict\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0;34m'cep'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0;34m'cidade'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'N/D'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;34m'estado'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'NI'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m   }\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'address_dict' where it is not associated with a value"
          ]
        }
      ]
    }
  ]
}